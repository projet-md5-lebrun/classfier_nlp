# Introduction 

f => loss function 
x => param du model 
=== 
Grandient descend formule (latex)
θj := θj - α * ∂/∂θj * J(θ0, θ1, ..., θn)


f(x) = f(x) - lr * grad(f(x)
SGD (latex)

ADAM => 

---

Polésimie dans le vecteur 


One hot encoding = 1 si le mot est présent, 0 sinon

World to vec



---
Worlds Embedding

=> Cosine similarity


One one encoding taille du vecteur = taille du vocabulaire
matrice embedding = taille du vocabulaire * sensibilité

Produit matriciel entre le vecteur one hot et la matrice embedding
Sortie => vecteur de sens 
